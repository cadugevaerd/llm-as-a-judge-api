# Troubleshooting Guide - LLM as Judge API

Guia completo para diagnÃ³stico e resoluÃ§Ã£o de problemas nos deployments Docker e Kubernetes.

## ðŸ” DiagnÃ³stico Geral

### VerificaÃ§Ãµes BÃ¡sicas

```bash
# Status da aplicaÃ§Ã£o
curl http://localhost:8000/api/v1/health/
curl http://localhost:8000/api/v1/health/detailed

# Verificar variÃ¡veis de ambiente
curl http://localhost:8000/api/v1/models/

# Teste de comparaÃ§Ã£o simples
curl -X POST http://localhost:8000/api/v1/compare/ \
  -H "Content-Type: application/json" \
  -d '{"input":"Teste","response_a":"A","response_b":"B"}'
```

## ðŸ³ Problemas Docker

### 1. Container nÃ£o inicia

#### Sintomas
```bash
$ docker-compose up -d
Creating llm-judge-api_llm-judge-api_1 ... error
```

#### DiagnÃ³stico
```bash
# Logs do container
docker-compose logs llm-judge-api

# Logs detalhados
docker-compose logs -f --tail=50 llm-judge-api

# Status dos containers
docker-compose ps
```

#### PossÃ­veis Causas e SoluÃ§Ãµes

**Porta jÃ¡ em uso:**
```bash
# Verificar quem estÃ¡ usando a porta 8000
lsof -i :8000
netstat -tulpn | grep :8000

# SoluÃ§Ã£o: parar processo ou mudar porta
docker-compose down
# ou editar docker-compose.yml para usar porta diferente
```

**Arquivo .env inexistente:**
```bash
# Verificar se .env existe
ls -la .env

# Criar .env baseado no exemplo
cp .env.example .env
# Editar .env com suas API keys
```

**Problema de permissÃµes:**
```bash
# Verificar permissÃµes dos arquivos
ls -la deploy/docker/

# Corrigir permissÃµes se necessÃ¡rio
chmod +x deploy/docker/Dockerfile*
```

### 2. API retorna erro 500

#### Sintomas
```bash
$ curl http://localhost:8000/api/v1/health/
{"detail":"Internal Server Error"}
```

#### DiagnÃ³stico
```bash
# Logs em tempo real
docker-compose logs -f llm-judge-api

# Executar bash no container
docker-compose exec llm-judge-api bash

# Testar Python dentro do container
docker-compose exec llm-judge-api python -c "from laaj.config import OPENROUTER_API_KEY; print('OK' if OPENROUTER_API_KEY else 'MISSING')"
```

#### PossÃ­veis Causas e SoluÃ§Ãµes

**API Key invÃ¡lida:**
```bash
# Testar API key manualmente
curl -H "Authorization: Bearer $OPENROUTER_API_KEY" \
  https://openrouter.ai/api/v1/models

# Verificar variÃ¡veis de ambiente no container
docker-compose exec llm-judge-api env | grep API_KEY
```

**DependÃªncias nÃ£o instaladas:**
```bash
# Rebuild sem cache
docker-compose build --no-cache

# Verificar instalaÃ§Ã£o dentro do container
docker-compose exec llm-judge-api uv list
```

### 3. Hot reload nÃ£o funciona

#### Sintomas
- MudanÃ§as no cÃ³digo nÃ£o sÃ£o refletidas automaticamente

#### SoluÃ§Ãµes
```bash
# Verificar se override existe
cat docker-compose.override.yml

# Criar override para desenvolvimento
cat > docker-compose.override.yml << EOF
version: '3.8'
services:
  llm-judge-api:
    volumes:
      - "../../src:/app/src"
    environment:
      - LOG_LEVEL=DEBUG
    command: uvicorn laaj.api.main:app --host 0.0.0.0 --port 8000 --reload
EOF

# Restart com override
docker-compose down && docker-compose up -d
```

### 4. Performance lenta

#### DiagnÃ³stico
```bash
# Monitor recursos
docker stats

# Logs de performance
docker-compose logs | grep -i "slow\|timeout\|error"
```

#### SoluÃ§Ãµes
```bash
# Ajustar recursos no docker-compose.yml
services:
  llm-judge-api:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'  
          memory: 1G
```

## â˜¸ï¸ Problemas Kubernetes

### 1. Pod em CrashLoopBackOff

#### Sintomas
```bash
$ kubectl get pods
NAME                            READY   STATUS             RESTARTS   AGE
llm-judge-api-xxx-yyy          0/1     CrashLoopBackOff   5          5m
```

#### DiagnÃ³stico
```bash
# Logs do pod atual
kubectl logs llm-judge-api-xxx-yyy

# Logs do container anterior (se crashou)
kubectl logs llm-judge-api-xxx-yyy --previous

# Describe pod para ver eventos
kubectl describe pod llm-judge-api-xxx-yyy

# Eventos do namespace
kubectl get events --sort-by=.metadata.creationTimestamp
```

#### PossÃ­veis Causas e SoluÃ§Ãµes

**API Key nÃ£o configurada:**
```bash
# Verificar se secret existe
kubectl get secret

# Verificar conteÃºdo do secret
kubectl get secret llm-judge-secrets -o yaml

# Recriar secret
kubectl delete secret llm-judge-secrets
python deploy_helm.py  # Recria com .env atual
```

**Resource limits muito baixos:**
```bash
# Ver resource usage atual
kubectl top pod llm-judge-api-xxx-yyy

# Aumentar limits no values.yaml
resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

# Upgrade
helm upgrade llm-judge-api deploy/helm/llm-judge-api/
```

**Imagem nÃ£o encontrada:**
```bash
# Verificar se imagem existe
kubectl describe pod llm-judge-api-xxx-yyy | grep -i image

# Build e push da imagem
docker build -t llm-judge-api:latest .
docker tag llm-judge-api:latest localhost:30500/llm-judge-api:latest  
docker push localhost:30500/llm-judge-api:latest
```

### 2. Service nÃ£o responde

#### Sintomas
```bash
$ kubectl port-forward svc/llm-judge-api 8080:8000
# Connection refused ou timeout
```

#### DiagnÃ³stico
```bash
# Verificar service
kubectl get svc llm-judge-api

# Endpoints do service  
kubectl get endpoints llm-judge-api

# Describe service
kubectl describe svc llm-judge-api
```

#### SoluÃ§Ãµes

**Labels nÃ£o coincidem:**
```bash
# Verificar labels do deployment
kubectl get deployment llm-judge-api -o yaml | grep -A5 labels

# Verificar selector do service
kubectl get svc llm-judge-api -o yaml | grep -A5 selector

# Devem coincidir - se nÃ£o, corrigir templates Helm
```

**Porta incorreta:**
```bash
# Verificar porta no deployment
kubectl get deployment llm-judge-api -o yaml | grep containerPort

# Verificar porta no service
kubectl get svc llm-judge-api -o yaml | grep port

# Corrigir values.yaml se necessÃ¡rio
```

### 3. Readiness probe falha

#### Sintomas
```bash
$ kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
llm-judge-api-xxx-yyy          0/1     Running   0          2m
```

#### DiagnÃ³stico
```bash
# Ver eventos do pod
kubectl describe pod llm-judge-api-xxx-yyy | grep -A10 Events

# Testar endpoint de health manualmente
kubectl exec -it llm-judge-api-xxx-yyy -- curl localhost:8000/api/v1/health
```

#### SoluÃ§Ãµes

**Health endpoint nÃ£o responde:**
```bash
# Aumentar initialDelaySeconds
readinessProbe:
  httpGet:
    path: /api/v1/health
    port: http
  initialDelaySeconds: 30  # Era 5
  periodSeconds: 10
```

**API demora para inicializar:**
```bash
# Verificar logs de startup
kubectl logs llm-judge-api-xxx-yyy | grep -i "started\|ready"

# Ajustar probe delays
livenessProbe:
  initialDelaySeconds: 60
readinessProbe:
  initialDelaySeconds: 30
```

### 4. Ingress nÃ£o funciona

#### Sintomas
- curl para host retorna 404 ou timeout

#### DiagnÃ³stico
```bash
# Verificar ingress
kubectl get ingress

# Describe ingress
kubectl describe ingress llm-judge-api

# Verificar ingress controller
kubectl get pods -n ingress-nginx
```

#### SoluÃ§Ãµes

**Host nÃ£o configurado no /etc/hosts:**
```bash
# Adicionar host local (desenvolvimento)
echo "127.0.0.1 llm-judge-api.local" | sudo tee -a /etc/hosts

# Testar
curl http://llm-judge-api.local/api/v1/health/
```

**Ingress class incorreta:**
```bash
# Verificar classes disponÃ­veis
kubectl get ingressclass

# Atualizar values.yaml
ingress:
  enabled: true
  className: "nginx"  # ou a classe correta
```

### 5. HPA nÃ£o escala

#### Sintomas
```bash
$ kubectl get hpa
NAME            REFERENCE                  TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
llm-judge-api   Deployment/llm-judge-api   <unknown>/70%   2         10        2          5m
```

#### DiagnÃ³stico
```bash
# Verificar metrics-server
kubectl top nodes
kubectl top pods

# Describe HPA
kubectl describe hpa llm-judge-api
```

#### SoluÃ§Ãµes

**Metrics-server nÃ£o instalado:**
```bash
# Instalar metrics-server (k3s, minikube)
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Para k3s, pode precisar de flags especÃ­ficos
```

**Resource requests nÃ£o definidas:**
```bash
# HPA precisa de requests definidas
resources:
  requests:
    cpu: 250m      # ObrigatÃ³rio para HPA
    memory: 512Mi
```

## ðŸ§ª Problemas da API

### 1. Timeout em comparaÃ§Ãµes

#### Sintomas
```bash
$ curl -X POST .../compare/ -d '{...}' 
{"detail":"Request timeout"}
```

#### SoluÃ§Ãµes
```bash
# Aumentar timeout no .env
WORKFLOW_TIMEOUT_SECONDS=180

# Redeploy
docker-compose down && docker-compose up -d
# ou
helm upgrade llm-judge-api deploy/helm/llm-judge-api/
```

### 2. Modelo judge nÃ£o responde

#### Sintomas
- API retorna erro sobre modelo nÃ£o disponÃ­vel

#### DiagnÃ³stico
```bash
# Testar API do OpenRouter diretamente
curl -H "Authorization: Bearer $OPENROUTER_API_KEY" \
  https://openrouter.ai/api/v1/models | jq '.data[] | select(.id | contains("llama-4-maverick"))'
```

#### SoluÃ§Ãµes
```bash
# Verificar modelos disponÃ­veis
curl http://localhost:8000/api/v1/models/

# Testar modelo especÃ­fico
curl -X POST http://localhost:8000/api/v1/compare/ \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Test", 
    "response_a": "A", 
    "response_b": "B"
  }'
```

### 3. LangSmith tracing nÃ£o funciona

#### Sintomas
- Logs nÃ£o mostram tracing ativo
- LangSmith dashboard nÃ£o recebe dados

#### SoluÃ§Ãµes
```bash
# Verificar variÃ¡veis LangSmith
echo $LANGSMITH_API_KEY
echo $LANGSMITH_PROJECT_NAME

# Testar conectividade
curl -H "x-api-key: $LANGSMITH_API_KEY" \
  https://api.smith.langchain.com/info

# Ativar tracing explicitamente
export LANGSMITH_TRACING=true
```

## ðŸ“Š Monitoring e Logs

### Coleta de Logs para Suporte

#### Docker
```bash
# Export all logs
docker-compose logs > debug-docker-$(date +%Y%m%d-%H%M).log

# Com timestamps
docker-compose logs -t > debug-docker-timestamps-$(date +%Y%m%d-%H%M).log
```

#### Kubernetes
```bash
# Export pod logs
kubectl logs deployment/llm-judge-api > debug-k8s-$(date +%Y%m%d-%H%M).log

# Export cluster info
kubectl describe deployment llm-judge-api > debug-deployment-$(date +%Y%m%d-%H%M).txt
kubectl get events --sort-by=.metadata.creationTimestamp > debug-events-$(date +%Y%m%d-%H%M).txt
```

### Debugging Checklist

#### Antes de solicitar ajuda:

1. **Logs coletados** âœ…
2. **ConfiguraÃ§Ã£o testada** âœ…
3. **API Keys validadas** âœ…
4. **Health checks verificados** âœ…
5. **VersÃµes documentadas** âœ…

```bash
# Version info
echo "=== ENVIRONMENT INFO ===" > debug-info.txt
date >> debug-info.txt
echo "Docker version:" >> debug-info.txt
docker --version >> debug-info.txt
echo "Docker Compose version:" >> debug-info.txt  
docker-compose --version >> debug-info.txt
echo "Kubernetes version:" >> debug-info.txt
kubectl version --client >> debug-info.txt
echo "Helm version:" >> debug-info.txt
helm version >> debug-info.txt
echo "=======================" >> debug-info.txt
```

---

## ðŸ†˜ Recursos de EmergÃªncia

### Reset Completo Docker
```bash
docker-compose down -v
docker system prune -a -f
docker-compose build --no-cache
docker-compose up -d
```

### Reset Completo Kubernetes  
```bash
helm uninstall llm-judge-api
kubectl delete secret llm-judge-secrets
kubectl delete configmap llm-judge-api-config
helm install llm-judge-api deploy/helm/llm-judge-api/ \
  --values deploy/helm/llm-judge-api/values-dev.yaml
```

### Contato
- Para problemas crÃ­ticos, documente: logs, configuraÃ§Ã£o, versÃµes e passos reprodutÃ­veis
- Anexe arquivos debug-*.txt e debug-*.log gerados acima