# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Task Master AI Instructions
**Import Task Master's development workflow commands and guidelines, treat as if import is in the main CLAUDE.md file.**
@./.taskmaster/CLAUDE.md

## Project Overview

Este √© um projeto de estudo sobre **LLM as Judge** - um sistema simplificado que compara e avalia respostas pr√©-geradas de diferentes modelos de linguagem usando um modelo judge. O sistema foi redesenhado para trabalhar APENAS com respostas j√° existentes, focando na compara√ß√£o e avalia√ß√£o.

## Architecture

### Core Components

- **laaj.config**: Configura√ß√£o centralizada de modelos (Claude, Gemini) via OpenRouter API
- **laaj.agents**: 
  - Factory functions simplificadas para criar inst√¢ncias de LLMs judge
  - `chain_laaj()`: √önica chain necess√°ria para avalia√ß√£o usando prompt do LangSmith
- **laaj.workflow**: Workflow simplificado contendo apenas o n√≥ `judge` para compara√ß√£o
- **laaj.api**: FastAPI REST API com endpoint `/api/v1/compare/` para compara√ß√£o via HTTP
- **laaj.langsmith_integration**: Cliente para tracing e observabilidade

### Simplified Workflow Architecture

O workflow atual (`src/laaj/workflow/workflow.py`) implementa arquitetura simplificada:

1. **Input**: Pergunta + duas respostas pr√©-geradas (response_a, response_b)
2. **Judge Node**: √önico n√≥ que usa modelo judge para comparar as respostas
3. **Output**: Resultado da compara√ß√£o ("A", "B", "Empate" ou erro)

**Estado**: `ComparisonState` cont√©m apenas input, response_a, response_b e resultado do judge.

### Judge System Details

- **Prompt**: Usa "laaj-prompt" do LangSmith Hub
- **Modelos suportados**: Claude 4 Sonnet (principal), Gemini 2.5 Pro, GPT-5, Qwen 3
- **Output parsing**: Suporta JSON estruturado e texto natural
- **Fallback**: Sistema robusto de interpreta√ß√£o quando JSON falha
- **Timeout**: 30 segundos por compara√ß√£o

### API Architecture

REST API (`src/laaj/api/`) implementada e funcional:
- **main.py**: FastAPI app com CORS habilitado para desenvolvimento
- **routers/compare.py**: Endpoint POST `/api/v1/compare/` integrado com workflow
- **schemas/compare.py**: Pydantic models `CompareRequest` e `ComparisonResponse`
- **routers/health.py**: Health checks b√°sicos e detalhados
- **routers/models.py**: Lista de modelos dispon√≠veis

### Supported Models

Configurados via OpenRouter API em `laaj.config.LITERAL_MODELS`:
- `claude-4-sonnet` - Anthropic Claude (modelo judge principal)
- `google-gemini-2.5-pro` - Google Gemini (alternativo)

Modelos adicionais dispon√≠veis via factory functions:
- `gpt-5-mini` - OpenAI GPT-5
- `qwen3-30b-a3b-instruct-2507` - Qwen 3 Instruct

## Development Commands

### Environment Setup
```bash
# Instalar depend√™ncias
uv sync

# Instalar depend√™ncias de desenvolvimento
uv sync --extra dev

# Ativar ambiente virtual
uv shell
```

### Running Code
```bash
# Executar workflow standalone (teste com respostas exemplo)
uv run src/laaj/workflow/workflow.py

# Executar API server (desenvolvimento com reload)
uv run uvicorn laaj.api.main:app --reload --port 8000

# Executar API server (produ√ß√£o)  
uv run src/laaj/api/main.py

# Testar LLMs individuais
uv run src/laaj/agents/llms.py

# Teste de tracing LangSmith
uv run scripts/test_tracing.py

# Executar Streamlit app (se dispon√≠vel)
uv run streamlit run src/laaj/app.py
```

### Development Tools
```bash
# Formata√ß√£o de c√≥digo (Black)
uv run black src/

# Linting (Ruff)
uv run ruff src/

# Testes (pytest - quando dispon√≠veis)
uv run pytest tests/
```

### Testing API Endpoints
```bash
# Testar API manualmente
curl -X POST "http://localhost:8000/api/v1/compare/" \
     -H "Content-Type: application/json" \
     -d '{
       "input": "Qual a capital do Brasil?",
       "response_a": "A capital do Brasil √© Bras√≠lia.",
       "response_b": "Bras√≠lia √© a capital do Brasil desde 1960."
     }'

# Health check
curl http://localhost:8000/api/v1/health/

# Swagger UI dispon√≠vel em
http://localhost:8000/docs
```

## Environment Variables Required

Criar arquivo `.env` na raiz:
```bash
# Required - OpenRouter API para todos os modelos
OPENROUTER_API_KEY=your_openrouter_key

# Optional - LangSmith para tracing e prompt hub
LANGSMITH_API_KEY=your_langsmith_key    
LANGSMITH_PROJECT_NAME=llm-as-judge-study
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# Optional - Workflow timeout (default: 120s)
WORKFLOW_TIMEOUT_SECONDS=120
```

## Key Patterns

### LLM Judge Factory Pattern
```python
from laaj.agents.llms import get_llm_anthropic_claude_4_sonnet
from laaj.agents import chain_laaj

# Criar inst√¢ncia do judge
judge_llm = get_llm_anthropic_claude_4_sonnet()
judge_chain = chain_laaj(judge_llm)  # Chain com prompt do LangSmith
```

### Workflow Usage Pattern
```python
from laaj.workflow.workflow import main as workflow_main

# Comparar duas respostas pr√©-geradas
result = await workflow_main(
    input_question="Qual a capital do Brasil?",
    response_a="A capital do Brasil √© Bras√≠lia.",
    response_b="Bras√≠lia √© a capital desde 1960.",
    model_a_name="claude-4-sonnet",  # opcional
    model_b_name="gemini-2.5-pro",  # opcional
    timeout_seconds=30
)
```

### API Request Pattern
```python
# CompareRequest schema
{
    "input": str,           # Pergunta/contexto original
    "response_a": str,      # Resposta A (obrigat√≥ria)
    "response_b": str,      # Resposta B (obrigat√≥ria)
    "model_a_name": str,    # Nome modelo A (opcional)
    "model_b_name": str     # Nome modelo B (opcional)
}

# ComparisonResponse schema
{
    "input": str,
    "response_a": str,
    "response_b": str,
    "model_a_name": str,
    "model_b_name": str,
    "better_response": str,      # "A", "B", "Empate", ou erro
    "judge_reasoning": str,      # Explica√ß√£o do judge
    "execution_time": float      # Tempo de execu√ß√£o
}
```

### Error Handling Pattern
- **Timeout**: Retorna `"TIMEOUT - Excedeu Xs"` em better_response
- **Validation**: Retorna `"ERRO - Valida√ß√£o falhou"` para inputs inv√°lidos  
- **LLM Error**: Retorna `"ERRO - Modelo judge n√£o dispon√≠vel"`
- **Parse Error**: Sistema de fallback tenta extrair resultado do texto

## Project Structure Insights

### Module Organization
```
src/laaj/
‚îú‚îÄ‚îÄ config/          # Configura√ß√£o centralizada de API keys e modelos
‚îú‚îÄ‚îÄ agents/          # LLM factories e chain creation 
‚îú‚îÄ‚îÄ workflow/        # Workflow simplificado (apenas judge)
‚îú‚îÄ‚îÄ api/            # FastAPI app com routers modulares
‚îî‚îÄ‚îÄ langsmith_integration/  # Cliente LangSmith
```

### State Management
- **ComparisonState**: TypedDict com campos m√≠nimos necess√°rios
- **Stateless**: Cada compara√ß√£o √© independente, sem persist√™ncia
- **Async**: Workflow totalmente ass√≠ncrono com timeout control

### LangSmith Integration
- **Automatic tracing**: Habilitado automaticamente quando LANGSMITH_API_KEY presente
- **Prompt management**: Judge usa prompt "laaj-prompt" do hub
- **Project tracking**: Traces organizados por LANGSMITH_PROJECT_NAME

## Current Development Status

### ‚úÖ Completed
- Workflow simplificado funcionando (apenas judge)
- API FastAPI totalmente integrada com workflow
- Schemas Pydantic implementados e validados
- Sistema robusto de error handling e timeout
- LLM factory functions para m√∫ltiplos modelos
- LangSmith integration para tracing

### üîÑ Current Focus
Sistema est√° funcional e pronto para uso. Pr√≥ximas melhorias dependem de requisitos espec√≠ficos.