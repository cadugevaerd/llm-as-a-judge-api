{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7575a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url_base = \"http://localhost:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eiur57l6oow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 === INICIANDO TESTE DE STRESS BATCH ===\n",
      "\n",
      "📊 Execução 1/3 - 5 comparações...\n",
      "   ✅ Sucesso - 5/5 comparações\n",
      "   ⏱️  Tempo API: 2.25s | Total: 2.26s\n",
      "   🏆 A:2 B:0 Empates:3 Erros:0\n",
      "\n",
      "📊 Execução 2/3 - 5 comparações...\n",
      "   ✅ Sucesso - 5/5 comparações\n",
      "   ⏱️  Tempo API: 1.89s | Total: 1.89s\n",
      "   🏆 A:2 B:0 Empates:3 Erros:0\n",
      "\n",
      "📊 Execução 3/3 - 5 comparações...\n",
      "   ✅ Sucesso - 5/5 comparações\n",
      "   ⏱️  Tempo API: 1.56s | Total: 1.56s\n",
      "   🏆 A:2 B:0 Empates:3 Erros:0\n",
      "\n",
      "📈 === ANÁLISE DE PERFORMANCE ===\n",
      "✅ Execuções bem-sucedidas: 3/3\n",
      "⏱️  Tempo médio API: 1.90s\n",
      "⏱️  Tempo médio total: 1.90s\n",
      "🚀 Comparações/segundo: 2.63\n",
      "📊 Total de comparações processadas: 15\n",
      "❌ Total de erros: 0\n",
      "🏃 Speedup estimado vs. individual: 1.0x\n",
      "\n",
      "🏆 === ESTATÍSTICAS AGREGADAS (todas as execuções) ===\n",
      "📊 Modelo A total: 6 vitórias\n",
      "📊 Modelo B total: 0 vitórias\n",
      "📊 Empates total: 9\n",
      "🎯 Taxa de decisão: 40.0%\n",
      "\n",
      "⏱️  Tempo total do teste: 5.71s\n",
      "🏁 === TESTE DE STRESS CONCLUÍDO ===\n"
     ]
    }
   ],
   "source": [
    "# TESTE DE STRESS SIMPLES\n",
    "import time\n",
    "\n",
    "def stress_test_batch():\n",
    "    \"\"\"\n",
    "    Teste de stress simples para o endpoint batch:\n",
    "    - Envia 5 comparações (máximo permitido)\n",
    "    - Mede tempos de resposta\n",
    "    - Verifica se todas as comparações foram processadas\n",
    "    - Compara performance com execuções individuais\n",
    "    \"\"\"\n",
    "    print(\"🚀 === INICIANDO TESTE DE STRESS BATCH ===\\n\")\n",
    "    \n",
    "    # Dados para o teste de stress (5 comparações - máximo permitido)\n",
    "    stress_data = {\n",
    "        \"comparisons\": [\n",
    "            {\n",
    "                \"input\": \"Qual a capital do Brasil?\",\n",
    "                \"response_a\": \"A capital do Brasil é Brasília, localizada no Distrito Federal.\",\n",
    "                \"response_b\": \"Brasília é a capital do Brasil desde 1960.\",\n",
    "                \"model_a_name\": \"claude-4-sonnet\",\n",
    "                \"model_b_name\": \"gemini-2.5-pro\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"Qual é o maior planeta do sistema solar?\",\n",
    "                \"response_a\": \"O maior planeta do sistema solar é Júpiter.\",\n",
    "                \"response_b\": \"Júpiter é o maior planeta, com massa maior que todos os outros planetas combinados.\",\n",
    "                \"model_a_name\": \"llama-4-maverick\",\n",
    "                \"model_b_name\": \"claude-4-sonnet\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"Quem foi Albert Einstein?\",\n",
    "                \"response_a\": \"Albert Einstein foi um físico teórico alemão.\",\n",
    "                \"response_b\": \"Einstein foi um físico que desenvolveu a teoria da relatividade.\",\n",
    "                \"model_a_name\": \"gemini-2.5-pro\", \n",
    "                \"model_b_name\": \"llama-4-maverick\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"O que é inteligência artificial?\",\n",
    "                \"response_a\": \"Inteligência artificial é a capacidade de máquinas realizarem tarefas que requerem inteligência humana.\",\n",
    "                \"response_b\": \"IA é um campo da ciência da computação focado em criar sistemas inteligentes.\",\n",
    "                \"model_a_name\": \"claude-4-sonnet\",\n",
    "                \"model_b_name\": \"gemini-2.5-pro\"\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"Como funciona o aquecimento global?\",\n",
    "                \"response_a\": \"O aquecimento global ocorre devido ao aumento de gases de efeito estufa na atmosfera.\",\n",
    "                \"response_b\": \"É o aumento da temperatura média da Terra causado pela atividade humana.\",\n",
    "                \"model_a_name\": \"llama-4-maverick\",\n",
    "                \"model_b_name\": \"claude-4-sonnet\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Fazer 3 execuções para verificar consistência\n",
    "    results = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        print(f\"📊 Execução {i}/3 - {len(stress_data['comparisons'])} comparações...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = safe_request(\"post\", url_base + endpoint, json=stress_data, timeout=120)  # timeout maior\n",
    "        execution_time = time.time() - start_time\n",
    "        total_time += execution_time\n",
    "        \n",
    "        if response and response.status_code == 200:\n",
    "            data = safe_json_response(response)\n",
    "            if data:\n",
    "                results.append({\n",
    "                    'execution': i,\n",
    "                    'status': 'success',\n",
    "                    'api_time': data['execution_time'],\n",
    "                    'total_time': execution_time,\n",
    "                    'comparisons': data['total_comparisons'],\n",
    "                    'successful': data['successful'],\n",
    "                    'errors': data['errors'],\n",
    "                    'model_a_wins': data['model_a_wins'],\n",
    "                    'model_b_wins': data['model_b_wins'],\n",
    "                    'ties': data['ties']\n",
    "                })\n",
    "                print(f\"   ✅ Sucesso - {data['successful']}/{data['total_comparisons']} comparações\")\n",
    "                print(f\"   ⏱️  Tempo API: {data['execution_time']:.2f}s | Total: {execution_time:.2f}s\")\n",
    "                print(f\"   🏆 A:{data['model_a_wins']} B:{data['model_b_wins']} Empates:{data['ties']} Erros:{data['errors']}\\n\")\n",
    "            else:\n",
    "                results.append({'execution': i, 'status': 'json_error'})\n",
    "                print(f\"   ❌ Erro ao processar JSON\\n\")\n",
    "        else:\n",
    "            results.append({'execution': i, 'status': 'request_error'})\n",
    "            print(f\"   ❌ Erro na requisição - Status: {response.status_code if response else 'None'}\\n\")\n",
    "    \n",
    "    # Análise dos resultados\n",
    "    print(\"📈 === ANÁLISE DE PERFORMANCE ===\")\n",
    "    successful_runs = [r for r in results if r['status'] == 'success']\n",
    "    \n",
    "    if successful_runs:\n",
    "        avg_api_time = sum(r['api_time'] for r in successful_runs) / len(successful_runs)\n",
    "        avg_total_time = sum(r['total_time'] for r in successful_runs) / len(successful_runs)\n",
    "        total_comparisons_processed = sum(r['successful'] for r in successful_runs)\n",
    "        total_errors = sum(r['errors'] for r in successful_runs)\n",
    "        \n",
    "        print(f\"✅ Execuções bem-sucedidas: {len(successful_runs)}/3\")\n",
    "        print(f\"⏱️  Tempo médio API: {avg_api_time:.2f}s\")\n",
    "        print(f\"⏱️  Tempo médio total: {avg_total_time:.2f}s\")\n",
    "        print(f\"🚀 Comparações/segundo: {5/avg_api_time:.2f}\")\n",
    "        print(f\"📊 Total de comparações processadas: {total_comparisons_processed}\")\n",
    "        print(f\"❌ Total de erros: {total_errors}\")\n",
    "        \n",
    "        # Comparação com processamento individual estimado\n",
    "        estimated_individual_time = avg_api_time / 5 * 5  # tempo por comparação * 5 (sequencial)\n",
    "        speedup = estimated_individual_time / avg_api_time if avg_api_time > 0 else 0\n",
    "        print(f\"🏃 Speedup estimado vs. individual: {speedup:.1f}x\")\n",
    "        \n",
    "        # Estatísticas agregadas\n",
    "        total_a_wins = sum(r['model_a_wins'] for r in successful_runs)\n",
    "        total_b_wins = sum(r['model_b_wins'] for r in successful_runs)\n",
    "        total_ties = sum(r['ties'] for r in successful_runs)\n",
    "        \n",
    "        print(f\"\\n🏆 === ESTATÍSTICAS AGREGADAS (todas as execuções) ===\")\n",
    "        print(f\"📊 Modelo A total: {total_a_wins} vitórias\")\n",
    "        print(f\"📊 Modelo B total: {total_b_wins} vitórias\") \n",
    "        print(f\"📊 Empates total: {total_ties}\")\n",
    "        \n",
    "        if total_a_wins + total_b_wins + total_ties > 0:\n",
    "            print(f\"🎯 Taxa de decisão: {((total_a_wins + total_b_wins) / (total_a_wins + total_b_wins + total_ties) * 100):.1f}%\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Todas as execuções falharam\")\n",
    "    \n",
    "    print(f\"\\n⏱️  Tempo total do teste: {total_time:.2f}s\")\n",
    "    print(\"🏁 === TESTE DE STRESS CONCLUÍDO ===\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Executar o teste de stress\n",
    "stress_results = stress_test_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a58c2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'LLM as Judge Study API', 'version': '0.1.0', 'endpoints': {'compare': '/api/v1/compare', 'models': '/api/v1/models', 'health': '/api/v1/health', 'docs': '/docs'}}\n"
     ]
    }
   ],
   "source": [
    "endpoint = \"/\"\n",
    "\n",
    "response = requests.get(url_base + endpoint)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99265519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Qual a capital do Brasil?', 'response_a': 'A capital do Brasil é Brasília, localizada no Distrito Federal.', 'response_b': 'Brasília é a capital do Brasil desde 1960.', 'better_response': 'Empate', 'judge_reasoning': None, 'model_a_name': None, 'model_b_name': None, 'timestamp': '2025-08-24T19:01:24.266315Z', 'execution_time': 1.162778377532959}\n"
     ]
    }
   ],
   "source": [
    "endpoint = \"/api/v1/compare\"\n",
    "\n",
    "data = {\n",
    "    \"input\": \"Qual a capital do Brasil?\",\n",
    "    \"response_a\": \"A capital do Brasil é Brasília, localizada no Distrito Federal.\",\n",
    "    \"response_b\": \"Brasília é a capital do Brasil desde 1960.\"\n",
    "}\n",
    "\n",
    "response = requests.post(url_base + endpoint, json=data, timeout=10)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "661456a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'available_models': ['llama-4-maverick', 'claude-4-sonnet', 'google-gemini-2.5-pro'], 'total_count': 3}\n"
     ]
    }
   ],
   "source": [
    "endpoint = \"/api/v1/models\"\n",
    "\n",
    "response = requests.get(url_base + endpoint, timeout=10)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28c63f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'healthy', 'timestamp': '2025-08-24T16:01:24.363909', 'service': 'LLM as Judge Study API', 'version': '0.1.0'}\n"
     ]
    }
   ],
   "source": [
    "endpoint = \"/api/v1/health\"\n",
    "\n",
    "response = requests.get(url_base + endpoint, timeout=10)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a833ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando testes do endpoint batch...\n",
      "\n",
      "=== TESTE 1: Request válido (2 comparações) ===\n",
      "Status: 200\n",
      "Response: {\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"id\": \"627f8b17-159b-47b8-9bb2-dd4da88eb82b\",\n",
      "      \"input\": \"Qual a capital do Brasil?\",\n",
      "      \"response_a\": \"A capital do Brasil é Brasília.\",\n",
      "      \"response_b\": \"Brasília é a capital do Brasil desde 1960.\",\n",
      "      \"model_a_name\": \"claude-4-sonnet\",\n",
      "      \"model_b_name\": \"gemini-2.5-pro\",\n",
      "      \"better_response\": \"Empate\",\n",
      "      \"judge_reasoning\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"962e1a85-9d73-4a98-9753-f0427f32ce33\",\n",
      "      \"input\": \"Qual é o maior planeta do sistema solar?\",\n",
      "      \"response_a\": \"O maior planeta do sistema solar é Júpiter.\",\n",
      "      \"response_b\": \"Júpiter é o maior planeta, com massa maior que todos os outros planetas combinados.\",\n",
      "      \"model_a_name\": \"llama-4-maverick\",\n",
      "      \"model_b_name\": \"claude-4-sonnet\",\n",
      "      \"better_response\": \"Empate\",\n",
      "      \"judge_reasoning\": null\n",
      "    }\n",
      "  ],\n",
      "  \"total_comparisons\": 2,\n",
      "  \"successful\": 2,\n",
      "  \"execution_time\": 1.3494327068328857,\n",
      "  \"model_a_wins\": 0,\n",
      "  \"model_b_wins\": 0,\n",
      "  \"ties\": 2,\n",
      "  \"errors\": 0,\n",
      "  \"best_model\": \"N/A\"\n",
      "}\n",
      "\n",
      "🏆 === ESTATÍSTICAS DE PERFORMANCE ===\n",
      "📊 Modelo A (vitórias): 0\n",
      "📊 Modelo B (vitórias): 0\n",
      "📊 Empates: 2\n",
      "📊 Erros: 0\n",
      "🥇 Melhor modelo geral: N/A\n",
      "⏱️ Tempo de execução: 1.35s\n",
      "\n",
      "=== TESTE 2: Request inválido (6 comparações - limite é 5) ===\n",
      "Status: 422\n",
      "Response: {\n",
      "  \"detail\": [\n",
      "    {\n",
      "      \"type\": \"too_long\",\n",
      "      \"loc\": [\n",
      "        \"body\",\n",
      "        \"comparisons\"\n",
      "      ],\n",
      "      \"msg\": \"List should have at most 5 items after validation, not 6\",\n",
      "      \"input\": [\n",
      "        {\n",
      "          \"input\": \"Pergunta 1\",\n",
      "          \"response_a\": \"Resposta A1\",\n",
      "          \"response_b\": \"Resposta B1\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"Pergunta 2\",\n",
      "          \"response_a\": \"Resposta A2\",\n",
      "          \"response_b\": \"Resposta B2\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"Pergunta 3\",\n",
      "          \"response_a\": \"Resposta A3\",\n",
      "          \"response_b\": \"Resposta B3\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"Pergunta 4\",\n",
      "          \"response_a\": \"Resposta A4\",\n",
      "          \"response_b\": \"Resposta B4\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"Pergunta 5\",\n",
      "          \"response_a\": \"Resposta A5\",\n",
      "          \"response_b\": \"Resposta B5\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"Pergunta 6\",\n",
      "          \"response_a\": \"Resposta A6\",\n",
      "          \"response_b\": \"Resposta B6\"\n",
      "        }\n",
      "      ],\n",
      "      \"ctx\": {\n",
      "        \"field_type\": \"List\",\n",
      "        \"max_length\": 5,\n",
      "        \"actual_length\": 6\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== TESTE 3: Apenas 1 comparação (deve sugerir endpoint individual) ===\n",
      "Status: 422\n",
      "Response: {\n",
      "  \"detail\": [\n",
      "    {\n",
      "      \"type\": \"too_short\",\n",
      "      \"loc\": [\n",
      "        \"body\",\n",
      "        \"comparisons\"\n",
      "      ],\n",
      "      \"msg\": \"List should have at least 2 items after validation, not 1\",\n",
      "      \"input\": [\n",
      "        {\n",
      "          \"input\": \"Qual a capital do Brasil?\",\n",
      "          \"response_a\": \"A capital do Brasil é Brasília.\",\n",
      "          \"response_b\": \"Brasília é a capital do Brasil desde 1960.\"\n",
      "        }\n",
      "      ],\n",
      "      \"ctx\": {\n",
      "        \"field_type\": \"List\",\n",
      "        \"min_length\": 2,\n",
      "        \"actual_length\": 1\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== TESTE 4: Lista vazia (deve dar erro - mínimo 2) ===\n",
      "Status: 422\n",
      "Response: {\n",
      "  \"detail\": [\n",
      "    {\n",
      "      \"type\": \"too_short\",\n",
      "      \"loc\": [\n",
      "        \"body\",\n",
      "        \"comparisons\"\n",
      "      ],\n",
      "      \"msg\": \"List should have at least 2 items after validation, not 0\",\n",
      "      \"input\": [],\n",
      "      \"ctx\": {\n",
      "        \"field_type\": \"List\",\n",
      "        \"min_length\": 2,\n",
      "        \"actual_length\": 0\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== TESTE 5: Sem payload (deve dar erro - campo obrigatório) ===\n",
      "Status: 422\n",
      "Response: {\n",
      "  \"detail\": [\n",
      "    {\n",
      "      \"type\": \"missing\",\n",
      "      \"loc\": [\n",
      "        \"body\",\n",
      "        \"comparisons\"\n",
      "      ],\n",
      "      \"msg\": \"Field required\",\n",
      "      \"input\": {}\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== TESTE 6: Sem JSON (deve dar erro - body vazio) ===\n",
      "Status: 422\n",
      "Response: {\n",
      "  \"detail\": [\n",
      "    {\n",
      "      \"type\": \"missing\",\n",
      "      \"loc\": [\n",
      "        \"body\"\n",
      "      ],\n",
      "      \"msg\": \"Field required\",\n",
      "      \"input\": null\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "✅ Testes concluídos!\n"
     ]
    }
   ],
   "source": [
    "# Definir configurações base\n",
    "url_base = \"http://localhost:8000\"\n",
    "endpoint = \"/api/v1/compare/batch\"\n",
    "\n",
    "# Dados de teste para o endpoint batch\n",
    "data_valid = {\n",
    "    \"comparisons\": [\n",
    "        {\n",
    "            \"input\": \"Qual a capital do Brasil?\",\n",
    "            \"response_a\": \"A capital do Brasil é Brasília.\",\n",
    "            \"response_b\": \"Brasília é a capital do Brasil desde 1960.\",\n",
    "            \"model_a_name\": \"claude-4-sonnet\",\n",
    "            \"model_b_name\": \"gemini-2.5-pro\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Qual é o maior planeta do sistema solar?\",\n",
    "            \"response_a\": \"O maior planeta do sistema solar é Júpiter.\",\n",
    "            \"response_b\": \"Júpiter é o maior planeta, com massa maior que todos os outros planetas combinados.\",\n",
    "            \"model_a_name\": \"llama-4-maverick\",\n",
    "            \"model_b_name\": \"claude-4-sonnet\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "data_invalid = {\n",
    "    \"comparisons\": [\n",
    "        {\"input\": \"Pergunta \" + str(i), \"response_a\": f\"Resposta A{i}\", \"response_b\": f\"Resposta B{i}\"}\n",
    "        for i in range(1, 7)  # 6 comparações - excede limite de 5\n",
    "    ]\n",
    "}\n",
    "\n",
    "data_single = {\n",
    "    \"comparisons\": [\n",
    "        {\n",
    "            \"input\": \"Qual a capital do Brasil?\",\n",
    "            \"response_a\": \"A capital do Brasil é Brasília.\",\n",
    "            \"response_b\": \"Brasília é a capital do Brasil desde 1960.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "data_empty = {\"comparisons\": []}\n",
    "\n",
    "data_no_payload = {}\n",
    "\n",
    "def safe_request(method, url, **kwargs):\n",
    "    \"\"\"Faz request com tratamento seguro de erros\"\"\"\n",
    "    try:\n",
    "        response = getattr(requests, method)(url, **kwargs)\n",
    "        return response\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Erro de conexão: {e}\")\n",
    "        return None\n",
    "\n",
    "def safe_json_response(response):\n",
    "    \"\"\"Extrai JSON com tratamento seguro de erros\"\"\"\n",
    "    if response is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return response.json()\n",
    "    except ValueError:\n",
    "        print(f\"Erro ao decodificar JSON. Status: {response.status_code}\")\n",
    "        print(f\"Raw response: {response.text[:200]}\")\n",
    "        return {\"error\": \"Invalid JSON response\", \"status_code\": response.status_code}\n",
    "\n",
    "def print_response_info(response, test_name):\n",
    "    \"\"\"Imprime informações da resposta de forma padronizada\"\"\"\n",
    "    print(f\"\\n=== {test_name} ===\")\n",
    "    \n",
    "    if response is None:\n",
    "        print(\"❌ Falha na conexão\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    \n",
    "    # Verificar se resposta tem conteúdo\n",
    "    if not response.text.strip():\n",
    "        print(\"❌ Resposta vazia\")\n",
    "        return\n",
    "        \n",
    "    response_data = safe_json_response(response)\n",
    "    \n",
    "    if response_data:\n",
    "        print(\"Response:\", json.dumps(response_data, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        # Destacar estatísticas de performance apenas para respostas 200\n",
    "        if response.status_code == 200 and 'model_a_wins' in response_data:\n",
    "            print(\"\\n🏆 === ESTATÍSTICAS DE PERFORMANCE ===\")\n",
    "            print(f\"📊 Modelo A (vitórias): {response_data['model_a_wins']}\")\n",
    "            print(f\"📊 Modelo B (vitórias): {response_data['model_b_wins']}\")\n",
    "            print(f\"📊 Empates: {response_data['ties']}\")\n",
    "            print(f\"📊 Erros: {response_data['errors']}\")\n",
    "            print(f\"🥇 Melhor modelo geral: {response_data['best_model']}\")\n",
    "            print(f\"⏱️ Tempo de execução: {response_data['execution_time']:.2f}s\")\n",
    "    else:\n",
    "        print(\"❌ Falha ao processar resposta JSON\")\n",
    "\n",
    "# Executar testes\n",
    "print(\"🚀 Iniciando testes do endpoint batch...\")\n",
    "\n",
    "# TESTE 1: Request válido\n",
    "response = safe_request(\"post\", url_base + endpoint, json=data_valid, timeout=30)\n",
    "print_response_info(response, \"TESTE 1: Request válido (2 comparações)\")\n",
    "\n",
    "# TESTE 2: Request inválido (muitas comparações)\n",
    "response = safe_request(\"post\", url_base + endpoint, json=data_invalid, timeout=30)\n",
    "print_response_info(response, \"TESTE 2: Request inválido (6 comparações - limite é 5)\")\n",
    "\n",
    "# TESTE 3: Request com apenas 1 comparação (deve sugerir endpoint individual)\n",
    "response = safe_request(\"post\", url_base + endpoint, json=data_single, timeout=30)\n",
    "print_response_info(response, \"TESTE 3: Apenas 1 comparação (deve sugerir endpoint individual)\")\n",
    "\n",
    "# TESTE 4: Lista vazia\n",
    "response = safe_request(\"post\", url_base + endpoint, json=data_empty, timeout=30)\n",
    "print_response_info(response, \"TESTE 4: Lista vazia (deve dar erro - mínimo 2)\")\n",
    "\n",
    "# TESTE 5: Sem payload\n",
    "response = safe_request(\"post\", url_base + endpoint, json=data_no_payload, timeout=30)\n",
    "print_response_info(response, \"TESTE 5: Sem payload (deve dar erro - campo obrigatório)\")\n",
    "\n",
    "# TESTE 6: Sem JSON\n",
    "response = safe_request(\"post\", url_base + endpoint, timeout=30)\n",
    "print_response_info(response, \"TESTE 6: Sem JSON (deve dar erro - body vazio)\")\n",
    "\n",
    "print(\"\\n✅ Testes concluídos!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
